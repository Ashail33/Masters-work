{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyMY1EE0EFNkYJ8DHaqUlg3D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashail33/Masters-work/blob/master/Clustering%20data%20creation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wil6vAzaCqas",
        "outputId": "200b90f5-9195-41f3-a11b-7c454830b50e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/Ashail33/mdcgenpy\n",
            "  Cloning https://github.com/Ashail33/mdcgenpy to /tmp/pip-req-build-nt451c5m\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Ashail33/mdcgenpy /tmp/pip-req-build-nt451c5m\n",
            "  Resolved https://github.com/Ashail33/mdcgenpy to commit 2e1580719361905a65ca58a42c039a3038276c95\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mdcgenpy==1.0.0) (1.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mdcgenpy==1.0.0) (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy->mdcgenpy==1.0.0) (1.22.4)\n",
            "Building wheels for collected packages: mdcgenpy\n",
            "  Building wheel for mdcgenpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mdcgenpy: filename=mdcgenpy-1.0.0-py3-none-any.whl size=24119 sha256=62df47454ee43c8f9cc402c847e588ded6ec95bd5e8ece2099a285f3ab8cab5b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9so3cfyl/wheels/17/85/f8/346c4006c2269fb848b0f7f13586b92df1aa0451d93761ec8b\n",
            "Successfully built mdcgenpy\n",
            "Installing collected packages: mdcgenpy\n",
            "Successfully installed mdcgenpy-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/Ashail33/mdcgenpy\n",
        "\n",
        "from  mdcgenpy import clusters as cl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# The properties I will be adding to the dataset are:\n",
        "#     1) Outliers - Binary ( two options) - outliers\n",
        "#     2) Noise - Binary ( two options) add_noise=0,n_noise=None,\n",
        "#     3) Number of clusters - I will select three values k\n",
        "#     4) Number of data points - I will select three values ( 100 000, 1 000 000, 100 000 000)n_samples\n",
        "#     5) Number of features - I will select five values ( 2, 10, 50, 100, 500) n_feats\n",
        "#     6) Density - I will select three values compactness_factor\n",
        "#     --7) Cluster shape - I will select three types - clusters within a radius ,  hollow shaped clusters , s-shaped / c-shaped clusters\n",
        "#      distributions\n",
        "#         'uniform': lambda shape, param: np.random.uniform(-param, param, shape),\n",
        "#     'gaussian': lambda shape, param: np.random.normal(0, param, shape),\n",
        "#     'logistic': lambda shape, param: np.random.logistic(0, param, shape),\n",
        "#     'triangular': lambda shape, param: np.random.triangular(-param, 0, param, shape),\n",
        "#     'gamma': lambda shape, param: np.random.gamma(2 + 8 * np.random.rand(), param / 5, shape),\n",
        "#     'gap': lambda shape, param: gap(shape, param)\n",
        "\n",
        "# --8) Missing values - this will need to be created by randomly removing values up to a certain number of columns and records\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zz=[[2,1,5],[3,4,3],[6,7,9]]"
      ],
      "metadata": {
        "id": "uqW6Mk8yTBSo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(zip(*zz))"
      ],
      "metadata": {
        "id": "7bor-mySUqkm",
        "outputId": "eb72a18a-6078-40c2-f862-7af4d0a93ade",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(2, 3, 6), (1, 4, 7), (5, 3, 9)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ,compactness_factor=[0.1,0.2,0.5,0.6,0.01],n_noise=[1,1,1,1,1]"
      ],
      "metadata": {
        "id": "f-W8SlpTd6AZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ['triangular','triangular','triangular','triangular','triangular']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrQVtehHn2fa",
        "outputId": "94dbdea7-1d3a-4ba3-ec4f-64f012e0a313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_gen=cl.ClusterGenerator(n_samples=1300000,k=[100000,100000,100000,100000,100000,400000,400000],compactness_factor=[0.1,0.2,0.3,0.4,0.5,0.7,0.1],n_feats=7,distributions=['uniform','triangular','normal','gamma','gap','gamma','normal'],scale=False,outliers=100,rotate=True,mv=[0,1,1,1,0,0,0],)"
      ],
      "metadata": {
        "id": "mefjM8H-F3Xk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cluster_gen=cl.ClusterGenerator(n_samples=100000,k=5,outliers= 500,n_feats=5,distributions='triangular')"
      ],
      "metadata": {
        "id": "79It0wuE3AQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data = cluster_gen.generate_data()\n",
        "# need to figure out where variable shape comes from and change that"
      ],
      "metadata": {
        "id": "C4g4ijqLkbuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get tuple with a numpy array with samples and another with labels\n",
        "data = cluster_gen.generate_data()\n",
        "\n",
        "y=pd.DataFrame(data[1])# labels\n",
        "y.columns=['cluster']\n",
        "\n",
        "x=pd.DataFrame(data[0],) # dataset with features\n",
        "\n",
        "zz=pd.concat([x,y],axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F-DJfuJFtrY",
        "outputId": "b4f81ab6-7267-495b-9c3d-173dbbf29140"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99614\n",
            "100068\n",
            "99925\n",
            "99963\n",
            "99599\n",
            "399453\n",
            "401274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "df = px.data.iris()\n",
        "fig = px.scatter_3d(zz, x=0, y=1, z=2,\n",
        "              color='cluster')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "izH7agXseflD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "df = px.data.iris()\n",
        "fig = px.scatter_3d(zz, x=0, y=1, z=2,\n",
        "              color='cluster')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "_TKqqR9TJozL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mdcgenpy import clusters as cl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Parameters for generating datasets\n",
        "outliers = [0, 500]\n",
        "noise_options = [(0, None), (0.1, 100)]\n",
        "n_clusters = [3, 5, 10]\n",
        "n_samples = [100_000, 1_000_000, 100_000_000]\n",
        "n_feats = [2, 10, 50, 100, 500]\n",
        "compactness_factors = [0.1, 0.5, 1]\n",
        "\n",
        "# Distributions for cluster shapes\n",
        "dist_options = ['uniform', 'gaussian', 'logistic', 'triangular', 'gamma', 'gap']\n",
        "\n",
        "datasets = []\n",
        "\n",
        "for outlier in outliers:\n",
        "    for add_noise, n_noise in noise_options:\n",
        "        for k in n_clusters:\n",
        "            for n_sample in n_samples:\n",
        "                for n_feat in n_feats:\n",
        "                    for compactness_factor in compactness_factors:\n",
        "                        for distribution in dist_options:\n",
        "                            distributions = [distribution] * k\n",
        "                            cluster_gen = cl.ClusterGenerator(\n",
        "                                n_samples=n_sample,\n",
        "                                outliers=outlier,\n",
        "                                n_feats=n_feat,\n",
        "                                k=k,\n",
        "                                distributions=distributions,\n",
        "                                compactness_factor=compactness_factor,\n",
        "                                add_noise=add_noise,\n",
        "                                n_noise=n_noise\n",
        "                            )\n",
        "                            data = cluster_gen.generate_data()\n",
        "                            datasets.append(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5pJEr2Vo5LyR",
        "outputId": "a7ac1d7c-3c10-4999-99b0-48b9e888462f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36377\n",
            "52464\n",
            "11159\n",
            "36377\n",
            "52464\n",
            "11159\n",
            "36377\n",
            "52464\n",
            "11159\n",
            "36377\n",
            "52464\n",
            "11159\n",
            "36377\n",
            "52464\n",
            "11159\n",
            "36377\n",
            "52464\n",
            "11159\n",
            "36377\n",
            "52464\n",
            "11159\n",
            "36377\n",
            "52464\n",
            "11159\n",
            "36377\n",
            "52464\n",
            "11159\n",
            "36377\n",
            "52464\n",
            "11159\n",
            "36377\n",
            "52464\n",
            "11159\n",
            "36377\n",
            "52464\n",
            "11159\n",
            "36377\n",
            "52464\n",
            "11159\n",
            "36377\n",
            "52464\n",
            "11159\n",
            "36377\n",
            "52464\n",
            "11159\n",
            "36377\n",
            "52464\n",
            "11159\n",
            "36377\n",
            "52464\n",
            "11159\n",
            "36377\n",
            "52464\n",
            "11159\n",
            "36298\n",
            "52605\n",
            "11097\n",
            "36298\n",
            "52605\n",
            "11097\n",
            "36298\n",
            "52605\n",
            "11097\n",
            "36298\n",
            "52605\n",
            "11097\n",
            "36298\n",
            "52605\n",
            "11097\n",
            "36298\n",
            "52605\n",
            "11097\n",
            "36298\n",
            "52605\n",
            "11097\n",
            "36298\n",
            "52605\n",
            "11097\n",
            "36298\n",
            "52605\n",
            "11097\n",
            "36298\n",
            "52605\n",
            "11097\n",
            "36298\n",
            "52605\n",
            "11097\n",
            "36298\n",
            "52605\n",
            "11097\n",
            "36298\n",
            "52605\n",
            "11097\n",
            "36298\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e2070c2355d8>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m                                 \u001b[0mn_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_noise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                             )\n\u001b[0;32m---> 36\u001b[0;31m                             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                             \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mdcgenpy/clusters/__init__.py\u001b[0m in \u001b[0;36mgenerate_data\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# if batch_size == 0, just return the data instead of the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mdcgenpy/clusters/generate.py\u001b[0m in \u001b[0;36mgenerate_clusters\u001b[0;34m(clus_cfg, batch_size)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclus_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclus_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclus_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mdcgenpy/clusters/generate.py\u001b[0m in \u001b[0;36mcompute_batch\u001b[0;34m(clus_cfg, n_samples)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# nr of samples in this cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr_matrix\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# apply correlation to data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mdcgenpy/clusters/__init__.py\u001b[0m in \u001b[0;36mgenerate_data\u001b[0;34m(self, samples)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;31m#                 print('self.mv'+str(self.mv))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;31m#                 print('self.compactness_factor'+str(self.compactness_factor))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompactness_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = []\n",
        "\n",
        "dataset_id = 0\n",
        "\n",
        "for outlier in outliers:\n",
        "    for add_noise, n_noise in noise_options:\n",
        "        for k in n_clusters:\n",
        "            for n_sample in n_samples:\n",
        "                for n_feat in n_feats:\n",
        "                    for compactness_factor in compactness_factors:\n",
        "                        for distribution in dist_options:\n",
        "                            distributions = [distribution] * k\n",
        "                            cluster_gen = cl.ClusterGenerator(\n",
        "                                n_samples=n_sample,\n",
        "                                outliers=outlier,\n",
        "                                n_feats=n_feat,\n",
        "                                k=k,\n",
        "                                distributions=distributions,\n",
        "                                compactness_factor=compactness_factor,\n",
        "                                add_noise=add_noise,\n",
        "                                n_noise=n_noise\n",
        "                            )\n",
        "                            data = cluster_gen.generate_data()\n",
        "                            \n",
        "                            dataset_properties = {\n",
        "                                'id': dataset_id,\n",
        "                                'outliers': outlier,\n",
        "                                'add_noise': add_noise,\n",
        "                                'n_noise': n_noise,\n",
        "                                'n_clusters': k,\n",
        "                                'n_samples': n_sample,\n",
        "                                'n_feats': n_feat,\n",
        "                                'compactness_factor': compactness_factor,\n",
        "                                'distribution': distribution,\n",
        "                                'data': data\n",
        "                            }\n",
        "                            \n",
        "                            datasets.append(dataset_properties)\n",
        "                            dataset_id += 1\n"
      ],
      "metadata": {
        "id": "GpuVBFZBUbd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client pandas"
      ],
      "metadata": {
        "id": "i1IvQiWtWNwe",
        "outputId": "582fe33a-dbb2-4166-8417-eeba34b643a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.10/dist-packages (0.1.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.84.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth) (4.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth) (1.16.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth) (0.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib) (1.3.1)\n",
            "Requirement already satisfied: httplib2>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-httplib2) (0.21.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.11.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.27.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.59.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2>=0.15.0->google-auth-httplib2) (3.0.9)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.0.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "from google.oauth2 import service_account\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=False)\n",
        "\n",
        "# Set the path to the 'Masters_data' folder in your Google Drive\n",
        "base_path = '/content/gdrive/MyDrive/'\n",
        "folder_name = 'Masters_data'\n",
        "folder_path = os.path.join(base_path, folder_name)\n",
        "\n",
        "# Create the 'Masters_data' folder if it doesn't exist\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n",
        "\n",
        "metadata = []\n",
        "dataset_id = 0\n",
        "\n",
        "for outlier in outliers:\n",
        "    for add_noise, n_noise in noise_options:\n",
        "        for k in n_clusters:\n",
        "            for n_sample in n_samples:\n",
        "                for n_feat in n_feats:\n",
        "                    for compactness_factor in compactness_factors:\n",
        "                        for distribution in dist_options:\n",
        "                            distributions = [distribution] * k\n",
        "                            cluster_gen = cl.ClusterGenerator(\n",
        "                                n_samples=n_sample,\n",
        "                                outliers=outlier,\n",
        "                                n_feats=n_feat,\n",
        "                                k=k,\n",
        "                                distributions=distributions,\n",
        "                                compactness_factor=compactness_factor,\n",
        "                                add_noise=add_noise,\n",
        "                                n_noise=n_noise\n",
        "                            )\n",
        "                            data = cluster_gen.generate_data()\n",
        "                            # print(\"First few elements of the generated data:\", data[:5])\n",
        "\n",
        "                            data_combined = np.concatenate(data, axis=1)\n",
        "                            df = pd.DataFrame(data_combined)\n",
        "                            \n",
        "                            file_name = f'dataset_{dataset_id}.csv'\n",
        "                            file_path = os.path.join(folder_path, file_name)\n",
        "                            df.to_csv(file_path, index=False)\n",
        "\n",
        "                            dataset_properties = {\n",
        "                                'id': dataset_id,\n",
        "                                'outliers': outlier,\n",
        "                                'add_noise': add_noise,\n",
        "                                'n_noise': n_noise,\n",
        "                                'n_clusters': k,\n",
        "                                'n_samples': n_sample,\n",
        "                                'n_feats': n_feat,\n",
        "                                'compactness_factor': compactness_factor,\n",
        "                                'distribution': distribution,\n",
        "                                'file_path': file_path\n",
        "                            }\n",
        "                            \n",
        "                            metadata.append(dataset_properties)\n",
        "                            dataset_id += 1\n",
        "\n",
        "metadata_file_path = os.path.join(folder_path, 'metadata.json')\n",
        "with open(metadata_file_path, 'w') as f:\n",
        "    json.dump(metadata, f)\n"
      ],
      "metadata": {
        "id": "CYraFMKlWOgq",
        "outputId": "8c6e01d9-26aa-4a88-9980-8536efa37746",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36803\n",
            "52097\n",
            "11100\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36776\n",
            "52121\n",
            "11103\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36788\n",
            "51930\n",
            "11282\n",
            "36377\n",
            "52464\n",
            "11159\n",
            "36377\n",
            "52464\n",
            "11159\n",
            "36377\n",
            "52464\n",
            "11159\n",
            "36377\n",
            "52464\n",
            "11159\n",
            "36377\n",
            "52464\n",
            "11159\n",
            "36377\n",
            "52464\n",
            "11159\n",
            "36377\n",
            "52464\n",
            "11159\n",
            "36377\n",
            "52464\n",
            "11159\n",
            "36377\n",
            "52464\n",
            "11159\n",
            "36377\n",
            "52464\n",
            "11159\n",
            "36377\n",
            "52464\n",
            "11159\n"
          ]
        }
      ]
    }
  ]
}