{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlJdKdUdv/xfy0Hg1X1o06",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashail33/Masters-work/blob/master/Cluster_eval_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVy1vnueJppI"
      },
      "outputs": [],
      "source": [
        "def davies_bouldin_index(data, clusters):\n",
        "\n",
        "  calculate means for each cluster\n",
        "  cluster_means = [np.mean(cluster, axis=0) for cluster in clusters]\n",
        "\n",
        "  #calculate intra-cluster distances\n",
        "  intra_cluster_distances = [np.mean([distance(point, cluster_mean) for point in cluster]) for cluster, cluster_mean in zip(clusters, cluster_means)]\n",
        "\n",
        "  #calculate inter-cluster distances\n",
        "  inter_cluster_distances = []\n",
        "  for i in range(len(clusters)):\n",
        "    distances = []\n",
        "      for j in range(len(clusters)):\n",
        "        if i != j:\n",
        "          distances.append(distance(cluster_means[i], cluster_means[j]))\n",
        "          inter_cluster_distances.append(max(distances))\n",
        "\n",
        "        #calculate Davies-Bouldin Index\n",
        "        db_index = 0\n",
        "        for i in range(len(clusters)):\n",
        "        db_index += intra_cluster_distances[i] / inter_cluster_distances[i]\n",
        "\n",
        "return db_index / len(clusters)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def intra_cluster_separation(clusters):\n",
        "\n",
        "#initialize variable to store sum of intra-cluster distances\n",
        "  intra_cluster_distance_sum = 0\n",
        "\n",
        "#calculate intra-cluster distances for each cluster and add to sum\n",
        "  for cluster in clusters:\n",
        "    for point1 in cluster:\n",
        "      for point2 in cluster:\n",
        "        intra_cluster_distance_sum += distance(point1, point2)\n",
        "\n",
        "#return average intra-cluster distance\n",
        "return intra_cluster_distance_sum / (len(clusters) * len(clusters[0]))"
      ],
      "metadata": {
        "id": "fEaxX3SRK6sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inter_cluster_separation(clusters):\n",
        "#initialize variable to store sum of inter-cluster distances\n",
        "  inter_cluster_distance_sum = 0\n",
        "\n",
        "#calculate inter-cluster distances for each pair of clusters and add to sum\n",
        "  for cluster1 in clusters:\n",
        "    for cluster2 in clusters:\n",
        "      if cluster1 != cluster2:\n",
        "        for point1 in cluster1:\n",
        "          for point2 in cluster2:\n",
        "            inter_cluster_distance_sum += distance(point1, point2)\n",
        "\n",
        "#return average inter-cluster distance\n",
        "return inter_cluster_distance_sum / (len(clusters) * len(clusters[0]) * (len(clusters) - 1))"
      ],
      "metadata": {
        "id": "GrGER3uxLS3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dunn_validity_index(clusters):\n",
        "\n",
        "  #calculate intra-cluster separation\n",
        "  intra_cluster_sep = intra_cluster_separation(clusters)\n",
        "\n",
        "  #calculate inter-cluster separation\n",
        "  inter_cluster_sep = inter_cluster_separation(clusters)\n",
        "\n",
        "  #calculate and return Dunn Validity Index\n",
        "return inter_cluster_sep / intra_cluster_sep"
      ],
      "metadata": {
        "id": "ro7d9FncMakp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cluster_accuracy(data, labels, clusters):\n",
        "\n",
        "  #initialize variable to store number of correctly classified points\n",
        "  correct_classifications = 0\n",
        "\n",
        "  #create a list of cluster assignments for each point in the data\n",
        "  cluster_assignments = [0 for _ in range(len(data))]\n",
        "  for i, cluster in enumerate(clusters):\n",
        "    for point in cluster:\n",
        "    cluster_assignments[data.index(point)] = i\n",
        "\n",
        "  #compare actual labels to cluster assignments and add to correct classifications count if they match\n",
        "  for i in range(len(data)):\n",
        "    if labels[i] == cluster_assignments[i]:\n",
        "      correct_classifications += 1\n",
        "\n",
        "#return accuracy as a percentage\n",
        "return correct_classifications / len(data) * 100"
      ],
      "metadata": {
        "id": "JFm5D05HMwlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adjusted_rand_index(data, labels, clusters):\n",
        "\n",
        "  #create a list of cluster assignments for each point in the data\n",
        "  cluster_assignments = [0 for _ in range(len(data))]\n",
        "  for i, cluster in enumerate(clusters):\n",
        "    for point in cluster:\n",
        "      cluster_assignments[data.index(point)] = i\n",
        "\n",
        "  #calculate number of pairs of points that are in the same cluster and have the same label\n",
        "  same_cluster_same_label = 0\n",
        "  for i in range(len(data)):\n",
        "    for j in range(i + 1, len(data)):\n",
        "      if cluster_assignments[i] == cluster_assignments[j] and labels[i] == labels[j]:\n",
        "        same_cluster_same_label += 1\n",
        "\n",
        "  #calculate number of pairs of points that are in the same cluster and have different labels\n",
        "  same_cluster_diff_label = 0\n",
        "  for i in range(len(data)):\n",
        "    for j in range(i + 1, len(data)):\n",
        "      if cluster_assignments[i] == cluster_assignments[j] and labels[i] != labels[j]:\n",
        "        same_cluster_diff_label += 1\n",
        "\n",
        "  #calculate number of pairs of points that are in different clusters and have the same label\n",
        "  diff_cluster_same_label = 0\n",
        "  for i in range(len(data)):\n",
        "    for j in range(i + 1, len(data)):\n",
        "      if cluster_assignments[i] != cluster_assignments[j] and labels[i] == labels[j]:\n",
        "        diff_cluster_same_label += 1\n",
        "\n",
        "  #calculate number of pairs of points that are in different clusters and have different labels\n",
        "  diff_cluster_diff_label = 0\n",
        "  for i in range(len(data)):\n",
        "    for j in range(i + 1, len(data)):\n",
        "      if cluster_assignments[i] != cluster_assignments[j] and labels[i] != labels[j]:\n",
        "        diff_cluster_diff_label += 1\n",
        "\n",
        "  #calculate expected index\n",
        "  expected_index = (same_cluster_same_label + diff_cluster_diff_label) / (same_cluster_same_label + same_cluster_diff_label + diff_cluster_same_label + diff_cluster_diff_label)\n",
        "\n",
        "  #calculate observed index\n",
        "  observed_index = (same_cluster_same_label + diff_cluster_diff_label) / (same_cluster_same_label + same_cluster_diff_label + diff_cluster_same_label + diff_cluster_diff_label)\n",
        "\n",
        "  #calculate and return adjusted rand index\n",
        "return (observed_index - expected_index) / (1 - expected_index)"
      ],
      "metadata": {
        "id": "YXPjuKdANehD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalised_mutual_information(data, labels, clusters):\n",
        "\n",
        "  #reate a list of cluster assignments for each point in the data\n",
        "  cluster_assignments = [0 for _ in range(len(data))]\n",
        "  for i, cluster in enumerate(clusters):\n",
        "    for point in cluster:\n",
        "      cluster_assignments[data.index(point)] = i\n",
        "\n",
        "  #calculate mutual information\n",
        "  mutual_info = 0\n",
        "  for i in range(len(data)):\n",
        "    for j in range(i + 1, len(data)):\n",
        "      if labels[i] == labels[j] and cluster_assignments[i] == cluster_assignments[j]:\n",
        "        mutual_info += 1\n",
        "\n",
        "  #calculate entropy of labels\n",
        "  label_entropy = 0\n",
        "  for label in set(labels):\n",
        "    label_prob = labels.count(label) / len(labels)\n",
        "    label_entropy -= label_prob * math.log(label_prob)\n",
        "\n",
        "  #calculate entropy of cluster assignments\n",
        "  cluster_entropy = 0\n",
        "  for cluster_assignment in set(cluster_assignments):\n",
        "    cluster_assignment_prob = cluster_assignments.count(cluster_assignment) / len(cluster_assignments)\n",
        "    cluster_entropy -= cluster_assignment_prob * math.log(cluster_assignment_prob)\n",
        "\n",
        "  #calculate and return normalised mutual information\n",
        "return mutual_info / math.sqrt(label_entropy * cluster_entropy)"
      ],
      "metadata": {
        "id": "eJuEfMdfOHbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clustering_stability(data, labels, clusters, num_repeats):\n",
        "\n",
        "  #initialize variable to store sum of cluster accuracies\n",
        "  accuracy_sum = 0\n",
        "\n",
        "  #repeat clustering multiple times and add accuracy to sum\n",
        "  for i in range(num_repeats):\n",
        "    accuracy_sum += cluster_accuracy(data, labels, clusters)\n",
        "\n",
        "#return average accuracy\n",
        "return accuracy_sum / num_repeats"
      ],
      "metadata": {
        "id": "yISFLcc1Oxw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "INYkUDgvO4An"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}