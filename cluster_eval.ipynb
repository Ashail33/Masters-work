{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqdjD8KRmjuZ7IRBdlpPYS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashail33/Masters-work/blob/master/cluster_eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GLvX7xUDl48I",
        "outputId": "05074d2e-960f-4e04-a982-6083588cb68a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error calculating cp: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating sp: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating db: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating dvi: A 2-dimensional array must be passed.\n",
            "Error calculating cp: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating sp: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating db: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating dvi: A 2-dimensional array must be passed.\n",
            "Error calculating cp: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating sp: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating db: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating dvi: A 2-dimensional array must be passed.\n",
            "Error calculating cp: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating sp: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating db: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating dvi: A 2-dimensional array must be passed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error calculating cp: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating sp: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating db: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating dvi: A 2-dimensional array must be passed.\n",
            "Error calculating cp: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating sp: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating db: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating dvi: A 2-dimensional array must be passed.\n",
            "Error calculating cp: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating sp: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating db: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating dvi: A 2-dimensional array must be passed.\n",
            "Error calculating cp: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Error calculating sp: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating db: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating dvi: A 2-dimensional array must be passed.\n",
            "Error calculating cp: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating sp: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating db: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating dvi: A 2-dimensional array must be passed.\n",
            "Error calculating cp: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating sp: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating db: Expected 2D array, got 1D array instead:\n",
            "array=[3 2 2 1 1 2 1 2 2 1 1 3 0 2 2 2 0 0 0 1 1 3 3 3 1 1 0 0 2 1 2 2 2 0 0 3 2\n",
            " 1 3 3 1 2 1 3 1 3 0 1 3 1 2 0 1 3 0 3 0 0 0 2 2 0 2 3 1 0 2 2 1 0 3 0 1 2\n",
            " 1 3 1 0 1 0 2 0 0 0 1 3 2 2 0 0 0 0 1 1 3 1 3 0 1 2 1 3 3 0 3 1 1 0 2 0 3\n",
            " 2 1 1 1 1 2 3 2 1 0 2 3 1 3 2 1 3 2 1 0 2 1 3 1 3 0 2 1 1 0 0 3 3 3 1 1 0\n",
            " 0 0 0 3 2 2 0 1 0 1 1 3 2 0 1 2 0 0 1 2 3 2 1 0 0 1 0 3 2 3 2 3 1 1 0 2 0\n",
            " 2 1 3 0 2 1 0 1 1 0 3 2 2 2 3 0 2 1 0 1 1 2 0 1 2 2 3 2 2 1 0 2 0 3 1 3 3\n",
            " 2 0 3 0 1 2 2 0 0 2 0 3 2 2 3 2 2 1 2 3 2 1 3 0 1 0 1 1 1 1 3 1 1 2 0 2 2\n",
            " 1 1 1 3 1 3 3 2 1 0 3 1 0 1 2 0 3 1 3 2 1 3 2 3 1 2 0 0 2 0 3 3 0 2 2 2 0\n",
            " 2 2 2 0 2 3 2 3 0 2 3 1 3 3 2 3 3 1 2 3 1 0 3 3 2 2 2 1 3 2 0 2 0 0 2 2 3\n",
            " 3 2 0 3 1 3 1 3 2 2 1 0 1 3 3 0 0 0 0 0 1 0 0 2 1 0 3 1 2 2 1 3 1 3 3 3 2\n",
            " 1 1 1 1 0 1 0 2 1 0 2 1 3 1 1 3 0 3 2 3 2 0 3 0 3 3 2 1 1 1 0 3 0 1 1 3 1\n",
            " 0 0 3 1 0 3 2 3 2 2 0 3 1 0 1 0 0 0 3 2 3 1 2 0 0 3 0 3 2 3 2 2 0 3 3 3 1\n",
            " 0 0 1 1 2 3 3 3 1 0 3 0 2 2 1 0 1 1 0 0 1 1 2 2 1 0 3 1 1 3 3 2 3 0 1 0 3\n",
            " 1 3 2 1 0 1 2 0 1 0 2 0 3 0 3 2 2 3 3 3 0 3 0 1 2 1 1 0 1 1 2 2 0 2 1 3 0\n",
            " 0 0 0 1 1 1 3 1 1 2 1 0 0 1 0 3 1 0 0 1 1 3 2 3 3 0 3 1 0 1 3 3 3 0 0 0 1\n",
            " 1 3 2 0 0 1 0 0 0 2 3 1 1 1 0 1 2 2 2 1 3 3 3 1 0 3 3 3 0 3 1 3 2 2 3 3 3\n",
            " 3 0 2 2 0 2 0 1 1 1 1 0 2 3 2 0 3 0 1 3 0 2 3 2 3 1 0 3 2 1 0 1 3 2 2 3 2\n",
            " 1 2 2 3 0 1 2 0 2 3 1 3 2 0 2 3 0 1 2 3 3 2 2 3 3 1 3 1 0 2 0 1 3 0 3 1 2\n",
            " 0 0 3 0 2 2 3 0 3 3 3 1 3 0 1 2 1 1 1 1 2 1 0 0 3 1 0 1 0 2 2 3 1 3 0 2 1\n",
            " 2 2 3 1 3 2 2 3 3 0 0 3 3 0 2 3 1 0 2 2 3 0 0 3 2 3 0 1 3 1 1 2 0 2 3 1 2\n",
            " 2 3 3 2 2 0 0 2 2 2 1 0 3 3 2 2 3 2 2 2 3 3 2 0 1 2 0 0 0 3 1 2 1 0 2 3 0\n",
            " 0 2 3 1 2 0 1 3 0 2 3 2 2 3 0 3 2 0 0 0 3 2 3 3 1 3 1 0 1 1 3 0 1 0 0 1 3\n",
            " 1 3 2 3 2 0 2 3 3 1 0 1 2 2 3 0 1 2 0 3 1 0 0 3 2 1 1 1 2 2 1 2 3 3 1 2 2\n",
            " 3 2 2 3 1 3 3 2 2 0 3 0 2 3 0 3 2 3 0 3 2 1 1 2 2 2 0 0 0 0 3 3 2 1 1 2 0\n",
            " 2 2 2 2 2 2 0 3 3 1 1 3 3 0 1 0 1 3 0 3 0 3 0 1 2 2 2 3 0 2 1 3 3 3 2 0 1\n",
            " 3 1 0 0 1 2 0 0 3 1 3 3 1 0 0 3 0 2 2 2 1 1 0 0 1 2 0 0 1 0 2 1 1 3 0 1 2\n",
            " 3 1 2 0 3 1 3 2 0 2 2 0 2 3 2 3 0 3 1 1 1 2 3 0 0 0 1 1 1 0 1 2 1 2 0 1 2\n",
            " 3].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "Error calculating dvi: A 2-dimensional array must be passed.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-f08ff08b5cf9>\u001b[0m in \u001b[0;36m<cell line: 245>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_blobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0malgorithm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_clustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-f08ff08b5cf9>\u001b[0m in \u001b[0;36mevaluate_clustering\u001b[0;34m(algorithm, dataset, true_labels, n_runs)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         summary[metric] = {\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0;34m'min'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m             \u001b[0;34m'max'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mamin\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2914\u001b[0m     \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2915\u001b[0m     \"\"\"\n\u001b[0;32m-> 2916\u001b[0;31m     return _wrapreduction(a, np.minimum, 'min', axis, None, out,\n\u001b[0m\u001b[1;32m   2917\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[1;32m   2918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '<=' not supported between instances of 'NoneType' and 'NoneType'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from sklearn.metrics import (\n",
        "    calinski_harabasz_score,\n",
        "    silhouette_score,\n",
        "    davies_bouldin_score,\n",
        "    adjusted_rand_score,\n",
        "    normalized_mutual_info_score,\n",
        "    adjusted_mutual_info_score,\n",
        ")\n",
        "from scipy.spatial.distance import pdist\n",
        "from itertools import combinations\n",
        "from sklearn.metrics import pairwise_distances\n",
        "import psutil\n",
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "from sklearn.metrics import pairwise_distances\n",
        "\n",
        "\n",
        "import psutil\n",
        "import time\n",
        "\n",
        "class Timer:\n",
        "    def __init__(self):\n",
        "        self.start_time = None\n",
        "        self.end_time = None\n",
        "\n",
        "    def __enter__(self):\n",
        "        self.start_time = time.perf_counter()\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_value, traceback):\n",
        "        self.end_time = time.perf_counter()\n",
        "\n",
        "    def elapsed_time(self):\n",
        "        if self.start_time is None or self.end_time is None:\n",
        "            return None\n",
        "        else:\n",
        "            return self.end_time - self.start_time\n",
        "\n",
        "\n",
        "class MemoryMonitor:\n",
        "    def __init__(self):\n",
        "        self.process = psutil.Process()\n",
        "        self.start_memory = None\n",
        "        self.end_memory = None\n",
        "\n",
        "    def __enter__(self):\n",
        "        self.start_memory = self.process.memory_info().rss\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_value, traceback):\n",
        "        self.end_memory = self.process.memory_info().rss\n",
        "\n",
        "    def memory_usage(self):\n",
        "        if self.start_memory is None or self.end_memory is None:\n",
        "            return None\n",
        "        else:\n",
        "            return self.end_memory - self.start_memory\n",
        "\n",
        "\n",
        "class DiskMonitor:\n",
        "    def __init__(self):\n",
        "        self.start_io_counters = None\n",
        "        self.end_io_counters = None\n",
        "\n",
        "    def __enter__(self):\n",
        "        self.start_io_counters = psutil.disk_io_counters()\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_value, traceback):\n",
        "        self.end_io_counters = psutil.disk_io_counters()\n",
        "\n",
        "    def disk_usage(self):\n",
        "        if self.start_io_counters is None or self.end_io_counters is None:\n",
        "            return None\n",
        "        else:\n",
        "            read_count = self\n",
        "\n",
        "\n",
        "def compactness(X, labels, metric='euclidean'):\n",
        "    \"\"\"\n",
        "    Calculate the compactness of a clustering result.\n",
        "\n",
        "    Parameters:\n",
        "        X (array-like): Data matrix.\n",
        "        labels (array-like): Cluster labels.\n",
        "        metric (string): Distance metric to use.\n",
        "\n",
        "    Returns:\n",
        "        float: Compactness value.\n",
        "    \"\"\"\n",
        "    n_clusters = len(set(labels))\n",
        "    distances = []\n",
        "    for i in range(n_clusters):\n",
        "        distances.append(pairwise_distances(X[labels == i], metric=metric))\n",
        "    return np.mean([np.sum(d) for d in distances]) / n_clusters\n",
        "\n",
        "def dunns_index(X, labels):\n",
        "    # Compute the diameter of each cluster (the maximum distance between any two points in the cluster)\n",
        "    diameters = np.zeros(len(set(labels)))\n",
        "    for i, label in enumerate(set(labels)):\n",
        "        indices = np.where(labels == label)[0]\n",
        "        if len(indices) <= 1:\n",
        "            diameters[i] = 0\n",
        "        else:\n",
        "            distances = pairwise_distances(X[indices])\n",
        "            diameters[i] = np.max(distances)\n",
        "    \n",
        "    # Compute the distance between cluster centers\n",
        "    centers = np.zeros((len(set(labels)), X.shape[1]))\n",
        "    for i, label in enumerate(set(labels)):\n",
        "        indices = np.where(labels == label)[0]\n",
        "        centers[i] = np.mean(X[indices], axis=0)\n",
        "    center_distances = pairwise_distances(centers)\n",
        "    \n",
        "    # Compute the Dunns index\n",
        "    min_intercluster_distance = np.min(center_distances[np.nonzero(center_distances)])\n",
        "    max_intracluster_diameter = np.max(diameters)\n",
        "    return min_intercluster_distance / max_intracluster_diameter\n",
        "\n",
        "\n",
        "def cluster_accuracy(y_true, y_pred):\n",
        "    from scipy.optimize import linear_sum_assignment\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    C = confusion_matrix(y_true, y_pred)\n",
        "    row_ind, col_ind = linear_sum_assignment(-C)\n",
        "    max_value = C[row_ind, col_ind].sum()\n",
        "    ca = max_value / np.sum(C)\n",
        "    return ca\n",
        "\n",
        "\n",
        "# def evaluate_clustering(algorithm, dataset, true_labels, n_runs=10):\n",
        "#     results = defaultdict(list)\n",
        "    \n",
        "#     metric_function_map = {\n",
        "#         'cp': calinski_harabasz_score,\n",
        "#         'sp': silhouette_score,\n",
        "#         'db': davies_bouldin_score,\n",
        "#         'dvi': dunn_index,\n",
        "#         'ca': cluster_accuracy,\n",
        "#         'ari': adjusted_rand_score,\n",
        "#         'nmi': normalized_mutual_info_score,\n",
        "#         'ami': adjusted_mutual_info_score,\n",
        "#         'stability': None\n",
        "#     }\n",
        "    \n",
        "#     for _ in range(n_runs):\n",
        "#         start_time = time.time()\n",
        "        \n",
        "#         algorithm.fit(dataset)\n",
        "#         labels = algorithm.labels_\n",
        "\n",
        "#         runtime = time.time() - start_time\n",
        "        \n",
        "#         for metric, func in metric_function_map.items():\n",
        "#             if func is not None:\n",
        "#                 value = func(dataset, labels)\n",
        "#                 results[metric].append(value)\n",
        "\n",
        "#         results['runtime'].append(runtime)\n",
        "    \n",
        "#     results_summary = {\n",
        "#         metric: {\n",
        "#             'mean': np.mean(values),\n",
        "#             'std': np.std(values),\n",
        "#             'min': np.min(values),\n",
        "#             'max': np.max(values)\n",
        "#         } for metric, values in results.items()\n",
        "#     }\n",
        "    \n",
        "#     return results_summary\n",
        "\n",
        "# # Example usage:\n",
        "# from sklearn.datasets import make_blobs\n",
        "# from sklearn.cluster import KMeans\n",
        "\n",
        "# X, y = make_blobs(n_samples=1000, centers=4, random_state=42)\n",
        "# algorithm = KMeans(n_clusters=4)\n",
        "# results = evaluate_clustering(algorithm, X, y)\n",
        "# print(results)\n",
        "\n",
        "def evaluate_clustering(algorithm, dataset, true_labels, n_runs=10):\n",
        "    results = defaultdict(list)\n",
        "    previous_runs_labels = []\n",
        "\n",
        "    metric_function_map = {\n",
        "        'cp': calinski_harabasz_score,\n",
        "        'sp': silhouette_score,\n",
        "        'db': davies_bouldin_score,\n",
        "        'dvi': dunn_index,\n",
        "        'ca': cluster_accuracy,\n",
        "        'ari': adjusted_rand_score,\n",
        "        'nmi': normalized_mutual_info_score,\n",
        "        'ami': adjusted_mutual_info_score,\n",
        "        \n",
        "    }\n",
        "\n",
        "    for _ in range(n_runs):\n",
        "        with Timer() as t, MemoryMonitor() as m, DiskMonitor() as d:\n",
        "            y_pred = algorithm.fit_predict(dataset)\n",
        "\n",
        "        for metric, func in metric_function_map.items():\n",
        "            try:\n",
        "                value = func(true_labels, y_pred)\n",
        "                results[metric].append(value)\n",
        "                if metric == 'stability':\n",
        "                  pass\n",
        "            except Exception as e:\n",
        "                print(f\"Error calculating {metric}: {e}\")\n",
        "                results[metric].append(None)\n",
        "            \n",
        "        # Compute Stability (using ARI) for the current run\n",
        "        for prev_labels in previous_runs_labels:\n",
        "            ari = adjusted_rand_score(prev_labels, true_labels)\n",
        "            results['stability'].append(ari)\n",
        "\n",
        "\n",
        "        with Timer() as t, MemoryMonitor() as m, DiskMonitor() as d:\n",
        "             y_pred = algorithm.fit_predict(dataset)\n",
        "             results['runtime'].append(t.elapsed_time)\n",
        "        results['ram_usage'].append(m.memory_usage)\n",
        "        results['disk_io'].append(d.disk_usage)\n",
        "\n",
        "\n",
        "    # Calculate min, max, mean, and std for each metric\n",
        "    summary = {}\n",
        "    for metric, values in results.items():\n",
        "        summary[metric] = {\n",
        "            'min': np.min(values),\n",
        "            'max': np.max(values),\n",
        "            'mean': np.mean(values),\n",
        "            'std': np.std(values),\n",
        "        }\n",
        "\n",
        "    return summary\n",
        "\n",
        "# Example usage:\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "X, y = make_blobs(n_samples=1000, centers=4, random_state=42)\n",
        "algorithm = KMeans(n_clusters=4)\n",
        "results = evaluate_clustering(algorithm, X, y)\n",
        "print(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_clustering(algorithm, dataset, true_labels, n_runs=10):\n",
        "    results = defaultdict(list)\n",
        "\n",
        "    metric_function_map = {\n",
        "        'cp': compactness,\n",
        "        'sp': separation,\n",
        "        'db': davies_bouldin_score,\n",
        "        'dvi': dunn_index,\n",
        "        'ca': cluster_accuracy,\n",
        "        'ari': adjusted_rand_score,\n",
        "        'nmi': normalized_mutual_info_score,\n",
        "        'sck': silhouette_score,\n",
        "    }\n",
        "\n",
        "    for _ in range(n_runs):\n",
        "        with Timer() as t, MemoryMonitor() as m, DiskMonitor() as d:\n",
        "            y_pred = algorithm.fit_predict(dataset)\n",
        "\n",
        "        for metric, func in metric_function_map.items():\n",
        "            try:\n",
        "                value = func(true_labels, y_pred)\n",
        "                results[metric].append(value)\n",
        "            except Exception as e:\n",
        "                print(f\"Error calculating {metric}: {e}\")\n",
        "                results[metric].append(None)\n",
        "\n",
        "        results['runtime'].append(t.interval)\n",
        "        results['ram_usage'].append(m.usage)\n",
        "        results['disk_io'].append(d.io)\n",
        "\n",
        "    # Calculate min, max, mean, and std for each metric\n",
        "    summary = {}\n",
        "    for metric, values in results.items():\n",
        "        summary[metric] = {\n",
        "            'min': np.min(values),\n",
        "            'max': np.max(values),\n",
        "            'mean': np.mean(values),\n",
        "            'std': np.std(values),\n",
        "        }\n",
        "\n",
        "    return summary\n",
        "\n",
        "from sklearn.metrics import pairwise_distances\n",
        "\n",
        "def compactness(X, labels, metric='euclidean'):\n",
        "    \"\"\"\n",
        "    Calculate the compactness of a clustering result.\n",
        "\n",
        "    Parameters:\n",
        "        X (array-like): Data matrix.\n",
        "        labels (array-like): Cluster labels.\n",
        "        metric (string): Distance metric to use.\n",
        "\n",
        "    Returns:\n",
        "        float: Compactness value.\n",
        "    \"\"\"\n",
        "    n_clusters = len(set(labels))\n",
        "    distances = []\n",
        "    for i in range(n_clusters):\n",
        "        distances.append(pairwise_distances(X[labels == i], metric=metric))\n",
        "    return np.mean([np.sum(d) for d in distances]) / n_clusters\n",
        "\n"
      ],
      "metadata": {
        "id": "C5dsseMGm6_Y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "X, y = make_blobs(n_samples=1000, centers=4, random_state=42)\n",
        "algorithm = KMeans(n_clusters=4)\n",
        "results = evaluate_clustering(algorithm, X, y)\n",
        "print(results)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "7yQJ3wXOm894",
        "outputId": "7d703861-03b2-4324-c7cc-5060c854e11e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-6acd28be7838>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_blobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0malgorithm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_clustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-dbc9320b22f2>\u001b[0m in \u001b[0;36mevaluate_clustering\u001b[0;34m(algorithm, dataset, true_labels, n_runs)\u001b[0m\n\u001b[1;32m      4\u001b[0m     metric_function_map = {\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m'cp'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcompactness\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;34m'sp'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mseparation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;34m'db'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdavies_bouldin_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;34m'dvi'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdunn_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'separation' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.metrics import davies_bouldin_score, silhouette_score, calinski_harabasz_score, adjusted_rand_score, normalized_mutual_info_score\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.spatial.distance import cdist\n",
        "import time\n",
        "import psutil\n",
        "import os\n",
        "\n",
        "\n",
        "class Timer:\n",
        "    def __enter__(self):\n",
        "        self.start_time = time.monotonic()\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        self.interval = time.monotonic() - self.start_time\n",
        "\n",
        "\n",
        "class MemoryMonitor:\n",
        "    def __enter__(self):\n",
        "        self.process = psutil.Process(os.getpid())\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        self.memory_info = self.process.memory_info()\n",
        "\n",
        "\n",
        "class DiskMonitor:\n",
        "    def __enter__(self):\n",
        "        self.disk_read_start = psutil.disk_io_counters().read_bytes\n",
        "        self.disk_write_start = psutil.disk_io_counters().write_bytes\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        self.disk_read_end = psutil.disk_io_counters().read_bytes\n",
        "        self.disk_write_end = psutil.disk_io_counters().write_bytes\n",
        "        self.disk_read_bytes = self.disk_read_end - self.disk_read_start\n",
        "        self.disk_write_bytes = self.disk_write_end - self.disk_write_start\n",
        "\n",
        "\n",
        "def compactness(X, labels):\n",
        "    centroids = np.array([np.mean(X[labels == i], axis=0) for i in set(labels)])\n",
        "    distances = cdist(X, centroids)\n",
        "    return np.sum(np.min(distances, axis=1))\n",
        "\n",
        "\n",
        "def separation(X, labels):\n",
        "    centroids = np.array([np.mean(X[labels == i], axis=0) for i in set(labels)])\n",
        "    return np.sum(cdist(centroids, centroids))\n",
        "\n",
        "\n",
        "def dunn_index(X, labels):\n",
        "    k = len(set(labels))\n",
        "    clusters = [X[labels == i] for i in range(k)]\n",
        "    cluster_distances = np.array([np.max(cdist(c1, c2)) for i, c1 in enumerate(clusters) for j, c2 in enumerate(clusters) if i < j])\n",
        "    return np.min(cdist(X, X)[np.array(labels)[:, None] != np.array(labels)[None, :]]) / np.max(cluster_distances)\n",
        "\n",
        "\n",
        "def evaluate_clustering(algorithm, dataset, true_labels=None, n_runs=10):\n",
        "    results = defaultdict(list)\n",
        "\n",
        "    metric_function_map = {\n",
        "        'cp': compactness,\n",
        "        'sp': separation,\n",
        "        'db': davies_bouldin_score,\n",
        "        'silhouette': silhouette_score,\n",
        "        'calinski_harabasz': calinski_harabasz_score,\n",
        "        'ari': adjusted_rand_score,\n",
        "        'nmi': normalized_mutual_info_score,\n",
        "        'dvi': dunn_index,\n",
        "    }\n",
        "\n",
        "    previous_runs_labels = []\n",
        "\n",
        "    for _ in range(n_runs):\n",
        "        with Timer() as t, MemoryMonitor() as m, DiskMonitor() as d:\n",
        "            labels = algorithm.fit_predict(dataset)\n",
        "\n",
        "        results['runtime'].append(t.interval)\n",
        "        results['memory'].append(m.memory_info.rss)\n",
        "        results['disk_read'].append(d.disk_read_bytes)\n",
        "        results['disk_write'].append(d.disk_write_bytes)\n",
        "\n",
        "        if true_labels is not None:\n",
        "          previous_runs_labels.append(labels)\n",
        "\n",
        "          results['runtime'].append(t.interval)\n",
        "          results['memory_usage'].append(m.memory_usage)\n",
        "          results['disk_usage'].append(d.disk_usage)\n",
        "\n",
        "          metric_results = {}\n",
        "\n",
        "          # Calculate clustering performance metrics\n",
        "          for metric_name, metric_function in metric_function_map.items():\n",
        "              try:\n",
        "                  value = metric_function(true_labels, labels, dataset)\n",
        "                  metric_results[metric_name] = value\n",
        "              except ValueError as e:\n",
        "                  print(f\"Error calculating {metric_name}: {e}\")\n",
        "                  metric_results[metric_name] = np.nan\n",
        "\n",
        "          # Calculate clustering stability metrics\n",
        "          for stability_name, stability_function in stability_function_map.items():\n",
        "              value = stability_function(previous_runs_labels, labels)\n",
        "              metric_results[stability_name] = value\n",
        "\n",
        "          # Add the current run's results to the list of previous runs\n",
        "          previous_runs_results.append(metric_results)\n",
        "\n",
        "      # Aggregate the results over all runs\n",
        "      for metric_name in metric_function_map.keys():\n",
        "          metric_values = [run_result[metric_name] for run_result in previous_runs_results]\n",
        "          results[f\"{metric_name}_mean\"].append(np.mean(metric_values))\n",
        "          results[f\"{metric_name}_std\"].append(np.std(metric_values))\n",
        "          results[f\"{metric_name}_max\"].append(np.max(metric_values))\n",
        "          results[f\"{metric_name}_min\"].append(np.min(metric_values))\n",
        "\n",
        "      for stability_name in stability_function_map.keys():\n",
        "          stability_values = [run_result[stability_name] for run_result in previous_runs_results]\n",
        "          results[f\"{stability_name}_mean\"].append(np.mean(stability_values))\n",
        "          results[f\"{stability_name}_std\"].append(np.std(stability_values))\n",
        "          results[f\"{stability_name}_max\"].append(np.max(stability_values))\n",
        "          results[f\"{stability_name}_min\"].append(np.min(stability_values))\n",
        "\n",
        "      results['model_id'].append(str(algorithm.__class__.__name__))\n",
        "      results['dataset_id'].append(str(dataset_id))\n",
        "\n",
        "  return results\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "e5AznwjNppQm",
        "outputId": "cc4eee98-ccae-4c5a-d45d-2d77f0cc3135"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m113\u001b[0m\n\u001b[0;31m    for metric_name in metric_function_map.keys():\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from sklearn.metrics import (\n",
        "    calinski_harabasz_score,\n",
        "    silhouette_score,\n",
        "    davies_bouldin_score,\n",
        "    adjusted_rand_score,\n",
        "    normalized_mutual_info_score,\n",
        "    adjusted_mutual_info_score,\n",
        ")\n",
        "from scipy.spatial.distance import pdist\n",
        "from itertools import combinations\n",
        "from sklearn.metrics import pairwise_distances\n",
        "import psutil\n",
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "from sklearn.metrics import pairwise_distances\n",
        "\n",
        "\n",
        "import psutil\n",
        "import time\n",
        "\n",
        "class Timer:\n",
        "    def __init__(self):\n",
        "        self.start_time = None\n",
        "        self.end_time = None\n",
        "\n",
        "    def __enter__(self):\n",
        "        self.start_time = time.perf_counter()\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_value, traceback):\n",
        "        self.end_time = time.perf_counter()\n",
        "\n",
        "    def elapsed_time(self):\n",
        "        if self.start_time is None or self.end_time is None:\n",
        "            return None\n",
        "        else:\n",
        "            return self.end_time - self.start_time\n",
        "\n",
        "\n",
        "class MemoryMonitor:\n",
        "    def __init__(self):\n",
        "        self.process = psutil.Process()\n",
        "        self.start_memory = None\n",
        "        self.end_memory = None\n",
        "\n",
        "    def __enter__(self):\n",
        "        self.start_memory = self.process.memory_info().rss\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_value, traceback):\n",
        "        self.end_memory = self.process.memory_info().rss\n",
        "\n",
        "    def memory_usage(self):\n",
        "        if self.start_memory is None or self.end_memory is None:\n",
        "            return None\n",
        "        else:\n",
        "            return self.end_memory - self.start_memory\n",
        "\n",
        "\n",
        "class DiskMonitor:\n",
        "    def __init__(self):\n",
        "        self.start_io_counters = None\n",
        "        self.end_io_counters = None\n",
        "\n",
        "    def __enter__(self):\n",
        "        self.start_io_counters = psutil.disk_io_counters()\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_value, traceback):\n",
        "        self.end_io_counters = psutil.disk_io_counters()\n",
        "\n",
        "    def disk_usage(self):\n",
        "        if self.start_io_counters is None or self.end_io_counters is None:\n",
        "            return None\n",
        "        else:\n",
        "            read_bytes_start = self.start_io_counters.read_bytes\n",
        "            read_bytes_end = self.end_io_counters.read_bytes\n",
        "            return read_bytes_end - read_bytes_start\n",
        "\n",
        "\n",
        "def compactness(X, labels, metric='euclidean'):\n",
        "    \"\"\"\n",
        "    Calculate the compactness of a clustering result.\n",
        "\n",
        "    Parameters:\n",
        "        X (array-like): Data matrix.\n",
        "        labels (array-like): Cluster labels.\n",
        "        metric (string): Distance metric to use.\n",
        "    Returns:\n",
        "        float: Compactness value.\n",
        "    \"\"\"\n",
        "    n_clusters = len(set(labels))\n",
        "    distances = []\n",
        "    for i in range(n_clusters):\n",
        "        distances.append(pairwise_distances(X[labels == i], metric=metric))\n",
        "    return np.mean([np.sum(d) for d in distances]) / n_clusters\n",
        "\n",
        "\n",
        "def dunns_index(X, labels):\n",
        "    # Compute the diameter of each cluster (the maximum distance between any two points in the cluster)\n",
        "    diameters = np.zeros(len(set(labels)))\n",
        "    for i, label in enumerate(set(labels)):\n",
        "        indices = np.where(labels == label)[0]\n",
        "        if len(indices) <= 1:\n",
        "            diameters[i] = 0\n",
        "        else:\n",
        "            distances = pairwise_distances(X[indices])\n",
        "            diameters[i] = np.max(distances)\n",
        "    \n",
        "    # Compute the distance between cluster centers\n",
        "    centers = np.zeros((len(set(labels)), X.shape[1]))\n",
        "    for i, label in enumerate(set(labels)):\n",
        "        indices = np.where(labels == label)[0]\n",
        "        centers[i] = np.mean(X[indices], axis=0)\n",
        "    center_distances = pairwise_distances(centers)\n",
        "    \n",
        "    # Compute the Dunns index\n",
        "    min_intercluster_distance = np.min(center_distances[np.nonzero(center_distances)])\n",
        "    max_intracluster_diameter = np.max(diameters)\n",
        "    return min_intercluster_distance / max_intracluster_diameter\n",
        "\n",
        "def cluster_separation(X, labels, metric='euclidean'):\n",
        "    \"\"\"\n",
        "    Calculate the cluster separation of a clustering result.\n",
        "\n",
        "    Parameters:\n",
        "        X (array-like): Data matrix.\n",
        "        labels (array-like): Cluster labels.\n",
        "        metric (string): Distance metric to use.\n",
        "\n",
        "    Returns:\n",
        "        float: Cluster separation value.\n",
        "    \"\"\"\n",
        "    n_clusters = len(set(labels))\n",
        "    centers = np.zeros((n_clusters, X.shape[1]))\n",
        "    for i, label in enumerate(set(labels)):\n",
        "        indices = np.where(labels == label)[0]\n",
        "        centers[i] = np.mean(X[indices], axis=0)\n",
        "    center_distances = pairwise_distances(centers, metric=metric)\n",
        "    return np.mean(center_distances)\n",
        "\n",
        "def cluster_accuracy(y_true, y_pred):\n",
        "    from scipy.optimize import linear_sum_assignment\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    C = confusion_matrix(y_true, y_pred)\n",
        "    row_ind, col_ind = linear_sum_assignment(-C)\n",
        "    max_value = C[row_ind, col_ind].sum()\n",
        "    ca = max_value / np.sum(C)\n",
        "    return ca\n",
        "\n",
        "def evaluate_clustering(algorithm, dataset, true_labels, n_runs=10):\n",
        "    results = defaultdict(list)\n",
        "    previous_runs_labels = []\n",
        "    for i in range(n_runs):\n",
        "        algorithm.fit(dataset)\n",
        "        labels = algorithm.labels_\n",
        "        if np.all(labels == previous_runs_labels):\n",
        "            continue\n",
        "        previous_runs_labels = labels\n",
        "        results['compactness'].append(compactness(dataset, labels))\n",
        "        results['dunn'].append(dunns_index(dataset, labels))\n",
        "        results['separation'].append(cluster_separation(dataset, labels))\n",
        "        results['accuracy'].append(cluster_accuracy(true_labels, labels))\n",
        "    return results\n",
        "\n"
      ],
      "metadata": {
        "id": "rZn0UDcpzbNH"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "X, y = make_blobs(n_samples=1000, centers=4, random_state=42)\n",
        "algorithm = KMeans(n_clusters=4)\n",
        "results = evaluate_clustering(algorithm, X, y)\n",
        "print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DApB2ZTs11-M",
        "outputId": "9fd626b2-de4e-4d36-e60c-88a3fada7b99"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-29-1b3c1e5a8be7>:160: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  if np.all(labels == previous_runs_labels):\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<class 'list'>, {'compactness': [27277.850471272344, 27277.850471272348, 27277.850471272348, 27277.850471272348, 27277.850471272348, 27277.850471272348, 27277.850471272344, 27277.850471272344, 27277.850471272348], 'dunn': [0.984275249606703, 0.984275249606703, 0.984275249606703, 0.984275249606703, 0.984275249606703, 0.984275249606703, 0.984275249606703, 0.984275249606703, 0.984275249606703], 'separation': [9.542390635919073, 9.542390635919071, 9.542390635919073, 9.542390635919071, 9.542390635919073, 9.542390635919071, 9.542390635919073, 9.542390635919071, 9.542390635919071], 'accuracy': [0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999]})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.datasets import make_blobs\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import calinski_harabasz_score\n",
        "\n",
        "def evaluate_clustering(algorithm, dataset, true_labels, n_runs=10):\n",
        "    results = defaultdict(list)\n",
        "    previous_runs_labels = []\n",
        "    for i in range(n_runs):\n",
        "        labels = algorithm.fit_predict(dataset)\n",
        "        if np.array_equal(labels, previous_runs_labels):\n",
        "            # Skip this run if the algorithm converged to the same solution as the previous run\n",
        "            continue\n",
        "        previous_runs_labels = labels\n",
        "        results[\"silhouette\"].append(silhouette_score(dataset, labels))\n",
        "        results[\"calinski_harabasz\"].append(calinski_harabasz_score(dataset, labels))\n",
        "        results[\"compactness\"].append(compactness(dataset, labels))\n",
        "        results[\"dunn\"].append(dunns_index(dataset, labels))\n",
        "        results[\"separation\"].append(cluster_separation(dataset, labels))\n",
        "        results[\"accuracy\"].append(cluster_accuracy(true_labels, labels))\n",
        "    return results\n",
        "\n",
        "# Generate synthetic data\n",
        "X, y = make_blobs(n_samples=1000, centers=4, random_state=42)\n",
        "\n",
        "# Run KMeans and DBSCAN clustering algorithms\n",
        "kmeans = KMeans(n_clusters=4)\n",
        "dbscan = DBSCAN(eps=1.0, min_samples=5)\n",
        "\n",
        "# Evaluate clustering algorithms\n",
        "results_kmeans = evaluate_clustering(kmeans, X, y)\n",
        "results_dbscan = evaluate_clustering(dbscan, X, y)\n",
        "\n",
        "# Check if the lengths of the results are the same\n",
        "if len(results_kmeans) != len(results_dbscan):\n",
        "    raise ValueError(\"The length of the results for KMeans and DBSCAN are different\")\n",
        "\n",
        "# Plot the results for KMeans\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.errorbar(\n",
        "    np.arange(1, len(results_kmeans) + 1),\n",
        "    [np.mean(v) for v in results_kmeans.values()],\n",
        "    [np.std(v) for v in results_kmeans.values()],\n",
        "    marker=\"o\",\n",
        "    label=\"KMeans\",\n",
        ")\n",
        "\n",
        "# Plot the results for DBSCAN\n",
        "plt.errorbar(\n",
        "    np.arange(1, len(results_dbscan) + 1),\n",
        "    [np.mean(v) for v in results_dbscan.values()],\n",
        "    [np.std(v) for v in results_dbscan.values()],\n",
        "    marker=\"o\",\n",
        "    label=\"DBSCAN\",\n",
        ")\n",
        "\n",
        "# Set the title and labels for the plot\n",
        "plt.title(\"Clustering Performance Comparison\")\n",
        "plt.xlabel(\"Metric\")\n",
        "plt.xticks(np.arange(1, len(results_kmeans) + 1), results_kmeans.keys())\n",
        "plt.ylabel(\"Score\")\n",
        "plt.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "id": "bdnleCjk3TXQ",
        "outputId": "c93f3f09-b2e0-460f-b58f-4bd5198f24ce"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-7c7b5655bb8a>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Evaluate clustering algorithms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mresults_kmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_clustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mresults_dbscan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_clustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdbscan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Check if the lengths of the results are the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-7c7b5655bb8a>\u001b[0m in \u001b[0;36mevaluate_clustering\u001b[0;34m(algorithm, dataset, true_labels, n_runs)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"silhouette\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msilhouette_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"calinski_harabasz\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalinski_harabasz_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compactness\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompactness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dunn\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdunns_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"separation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_separation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-1b3c1e5a8be7>\u001b[0m in \u001b[0;36mcompactness\u001b[0;34m(X, labels, metric)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mdistances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairwise_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   2037\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2039\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1579\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m     \u001b[0;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    298\u001b[0m            [1.41421356]])\n\u001b[1;32m    299\u001b[0m     \"\"\"\n\u001b[0;32m--> 300\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX_norm_squared\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mY\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mY\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         X = Y = check_array(\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;34m\"Found array with %d sample(s) (shape=%s) while a\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                 \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 2)) while a minimum of 1 is required by check_pairwise_arrays."
          ]
        }
      ]
    }
  ]
}